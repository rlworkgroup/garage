{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "custom_env.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rlworkgroup/garage/blob/master/examples/jupyter/custom_env.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "Za0nLGHy5jyP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Demonstrate usage of a custom openai/gym environment with rlworkgroup/garage"
      ]
    },
    {
      "metadata": {
        "id": "acXH8kwHsAYT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Demonstrate usage of [garage](https://github.com/rlworkgroup/garage) with a custom `openai/gym` environment in a jupyter notebook."
      ]
    },
    {
      "metadata": {
        "id": "GmPLYXrXH7A5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Install pre-requisites"
      ]
    },
    {
      "metadata": {
        "id": "Aj3bL9HaG5HL",
        "colab_type": "code",
        "outputId": "21508810-1b19-4f63-c1da-fdde3cb17e88",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 901
        }
      },
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "\n",
        "echo \"abcd\" > mujoco_fake_key\n",
        "\n",
        "\n",
        "git clone --depth 1 https://github.com/rlworkgroup/garage/\n",
        "\n",
        "cd garage\n",
        "bash scripts/setup_colab.sh --mjkey ../mujoco_fake_key --no-modify-bashrc > /dev/null"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'garage' already exists and is not an empty directory.\n",
            "start of setup_colab.sh\n",
            "\n",
            "WARNING: apt does not have a stable CLI interface. Use with caution in scripts.\n",
            "\n",
            "\n",
            "WARNING: apt does not have a stable CLI interface. Use with caution in scripts.\n",
            "\n",
            "\n",
            "WARNING: apt does not have a stable CLI interface. Use with caution in scripts.\n",
            "\n",
            "Cloning into '/tmp/tmp.4slNT9c4V6/glfw'...\n",
            "remote: Enumerating objects: 23479, done.\u001b[K\n",
            "remote: Total 23479 (delta 0), reused 0 (delta 0), pack-reused 23479\u001b[K\n",
            "Receiving objects: 100% (23479/23479), 11.64 MiB | 22.78 MiB/s, done.\n",
            "Resolving deltas: 100% (16458/16458), done.\n",
            "Note: checking out '0be4f3f75aebd9d24583ee86590a38e741db0904'.\n",
            "\n",
            "You are in 'detached HEAD' state. You can look around, make experimental\n",
            "changes and commit them, and you can discard any commits you make in this\n",
            "state without impacting any branches by performing another checkout.\n",
            "\n",
            "If you want to create a new branch to retain commits you create, you may\n",
            "do so (now or later) by using -b with the checkout command again. Example:\n",
            "\n",
            "  git checkout -b <new-branch-name>\n",
            "\n",
            "HEAD is now at 0be4f3f7 Add GLFW_FOCUS_ON_SHOW window hint and attribute\n",
            "Cloning into '/tmp/tmp.Xq2ekFYVDa/mujoco_150'...\n",
            "remote: Enumerating objects: 200, done.\u001b[K\n",
            "remote: Counting objects: 100% (200/200), done.\u001b[K\n",
            "remote: Compressing objects: 100% (192/192), done.\u001b[K\n",
            "remote: Total 200 (delta 7), reused 166 (delta 3), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (200/200), 2.98 MiB | 23.15 MiB/s, done.\n",
            "Resolving deltas: 100% (7/7), done.\n",
            "Note: checking out '3ba83940a957a0e2236aaa739fc6a8e8f5b7c421'.\n",
            "\n",
            "You are in 'detached HEAD' state. You can look around, make experimental\n",
            "changes and commit them, and you can discard any commits you make in this\n",
            "state without impacting any branches by performing another checkout.\n",
            "\n",
            "If you want to create a new branch to retain commits you create, you may\n",
            "do so (now or later) by using -b with the checkout command again. Example:\n",
            "\n",
            "  git checkout -b <new-branch-name>\n",
            "\n",
            "end of setup_colab.sh\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              ""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "metadata": {
        "id": "_FWFcZWCgjrm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "raise Exception(\"Please restart your runtime so that the installed dependencies for 'garage' can be loaded, and then resume running the notebook\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wCuJ9d-Jgk1Y",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "34oLOKVb5t8l",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# custom gym environment"
      ]
    },
    {
      "metadata": {
        "id": "oBv4mojWRT6v",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Create a gym env that simulates the current water treatment plant\n",
        "# Based on https://github.com/openai/gym/blob/master/gym/envs/toy_text/nchain.py\n",
        "\n",
        "import gym\n",
        "from gym import spaces\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "\n",
        "\n",
        "# Gym env\n",
        "class MyEnv(gym.Env):\n",
        "    \"\"\"Custom gym environment\n",
        "    \n",
        "    Observation: Coin flip (Discrete binary: 0/1)\n",
        "      \n",
        "    Actions: Guess of coin flip outcome (Discrete binary: 0/1)\n",
        "      \n",
        "    Reward: Guess the coin flip correctly\n",
        "      \n",
        "    Episode termination: Make 5 correct guesses within 20 attempts\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        # set action/observation spaces\n",
        "        self.action_space = spaces.Discrete(2)\n",
        "        self.observation_space = spaces.Discrete(2)\n",
        "        self.reset()\n",
        "\n",
        "    def step(self, action):\n",
        "        assert self.action_space.contains(action), \"action not in action space!\"\n",
        "        \n",
        "        # flip a coin\n",
        "        self.state = np.random.rand() < 0.5\n",
        "\n",
        "        # increment number of attempts\n",
        "        self.attempt += 1\n",
        "        \n",
        "        # calculate reward of this element\n",
        "        reward = (action == self.state)\n",
        "        self.score += reward\n",
        "          \n",
        "        # allow a maximum number of attempts or reach max score\n",
        "        done = (self.attempt >= 20) | (self.score >= 5)\n",
        "          \n",
        "        return self.state, reward, done, {}\n",
        "      \n",
        "    def reset(self):\n",
        "      # accumulate score\n",
        "      self.score = 0\n",
        "      # count number of attempts\n",
        "      self.attempt = 0\n",
        "      \n",
        "      return 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Xi3SwHSJO3xm",
        "colab_type": "code",
        "outputId": "d8557925-1e7c-4173-d2f2-ce035e5811be",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "cell_type": "code",
      "source": [
        "# some smoke testing\n",
        "env_test = MyEnv()\n",
        "observation = env_test.reset()\n",
        "\n",
        "for step in range(40):\n",
        "  action = np.random.rand() < 0.5\n",
        "  observation, reward, done, _ = env_test.step(action)\n",
        "  print(\"step %i: action=%i, observation=%i => reward = %i, done = %s\" % (step, action, observation, reward, done))\n",
        "  if done: break"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "step 0: action=0, observation=1 => reward = 0, done = False\n",
            "step 1: action=1, observation=0 => reward = 0, done = False\n",
            "step 2: action=0, observation=1 => reward = 0, done = False\n",
            "step 3: action=0, observation=0 => reward = 1, done = False\n",
            "step 4: action=1, observation=0 => reward = 0, done = False\n",
            "step 5: action=1, observation=0 => reward = 0, done = False\n",
            "step 6: action=1, observation=0 => reward = 0, done = False\n",
            "step 7: action=0, observation=1 => reward = 0, done = False\n",
            "step 8: action=0, observation=1 => reward = 0, done = False\n",
            "step 9: action=1, observation=1 => reward = 1, done = False\n",
            "step 10: action=1, observation=1 => reward = 1, done = False\n",
            "step 11: action=1, observation=0 => reward = 0, done = False\n",
            "step 12: action=0, observation=0 => reward = 1, done = False\n",
            "step 13: action=1, observation=1 => reward = 1, done = True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Nd-RbAhH6Kx8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Prepare training"
      ]
    },
    {
      "metadata": {
        "id": "9j8M1L9S6rvU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# The contents of this cell are mostly copied from garage/examples/...\n",
        "\n",
        "from garage.np.baselines import LinearFeatureBaseline # <<<<<< requires restarting the runtime in colab after the 1st dependency installation above\n",
        "from garage.envs import normalize\n",
        "#from garage.envs.box2d import CartpoleEnv # no need since will use WtpDesignerEnv_v0 defined above\n",
        "from garage.experiment import run_experiment\n",
        "from garage.tf.algos import TRPO\n",
        "from garage.tf.envs import TfEnv\n",
        "#from garage.tf.policies import GaussianMLPPolicy\n",
        "from garage.tf.policies import CategoricalMLPPolicy\n",
        "\n",
        "import gym # already imported before\n",
        "\n",
        "\n",
        "from garage.experiment import LocalRunner\n",
        "from garage.logger import logger, StdOutput"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UNoyVv0tA23n",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# register the env with gym\n",
        "# https://github.com/openai/gym/tree/master/gym/envs#how-to-create-new-environments-for-gym\n",
        "from gym.envs.registration import register\n",
        "\n",
        "register(\n",
        "    id='MyEnv-v0',\n",
        "    entry_point=MyEnv,\n",
        ")\n",
        "\n",
        "# test registration was successful\n",
        "env = gym.make(\"MyEnv-v0\")\n",
        "# env = TfEnv(normalize(gym.make(\"MyEnv-v0\")))\n",
        "# env = TfEnv(env_name='MyEnv-v0') "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tx8_cmOe63QK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Wrap the environment to convert the observation to numpy array\n",
        "# Not sure why this is necessary ATM\n",
        "# Based on https://github.com/openai/gym/blob/5404b39d06f72012f562ec41f60734bd4b5ceb4b/gym/wrappers/dict.py\n",
        "\n",
        "      \n",
        "# from gym import wrappers\n",
        "\n",
        "class NpWrapper(gym.ObservationWrapper):\n",
        "    def observation(self, observation):\n",
        "        obs = np.array(observation).astype('int')\n",
        "        return obs\n",
        "      \n",
        "      \n",
        "env = NpWrapper(env)\n",
        "env = TfEnv(normalize(env))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mpc-sCTvnlH7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "policy = CategoricalMLPPolicy(\n",
        "    name=\"policy\", env_spec=env.spec, hidden_sizes=(32, 32))\n",
        "\n",
        "baseline = LinearFeatureBaseline(env_spec=env.spec)\n",
        "\n",
        "\n",
        "algo = TRPO(\n",
        "    env_spec=env.spec,\n",
        "    policy=policy,\n",
        "    baseline=baseline,\n",
        "    max_path_length=50,\n",
        "    n_itr=50,\n",
        "    discount=0.99,\n",
        "    max_kl_step=0.01\n",
        ")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hFgHLyD7oRaH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Start training"
      ]
    },
    {
      "metadata": {
        "id": "v7LQO4zBp8h4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# log to stdout\n",
        "logger.add_output(StdOutput())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eBk8B2h36pMw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# start a tensorflow session so that we can keep it open after training and use the trained network to see it performing\n",
        "import tensorflow as tf\n",
        "sess = tf.InteractiveSession()\n",
        "\n",
        "# no need to initialize\n",
        "sess.run(tf.compat.v1.global_variables_initializer())\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mu0Vg3j8iK-q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 5209
        },
        "outputId": "dc07d5fb-1ddc-4ede-982c-096f872964c7"
      },
      "cell_type": "code",
      "source": [
        "# Train the policy (neural network) on the environment\n",
        "runner = LocalRunner()\n",
        "\n",
        "runner.setup(algo=algo, env=env)\n",
        "\n",
        "# use n_epochs = 2 for quick demo\n",
        "runner.train(n_epochs=2, batch_size=10000, plot=False)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2019-04-01 06:42:42 | epoch #0 | Obtaining samples...\n",
            "2019-04-01 06:42:42 | epoch #0 | Obtaining samples for iteration 0...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/garage/garage/experiment/local_tf_runner.py:129: LoggerWarning: \u001b[33mLog data of type Graph was not accepted by any output\u001b[0m\n",
            "  logger.log(self.sess.graph)\n",
            "0% [##############################] 100% | ETA: 00:00:00\n",
            "Total time elapsed: 00:00:06\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-04-01 06:42:49 | epoch #0 | Logging diagnostics...\n",
            "2019-04-01 06:42:49 | epoch #0 | Optimizing policy...\n",
            "2019-04-01 06:42:49 | epoch #0 | Computing loss before\n",
            "2019-04-01 06:42:49 | epoch #0 | Computing KL before\n",
            "2019-04-01 06:42:49 | epoch #0 | Optimizing\n",
            "2019-04-01 06:42:49 | epoch #0 | Start CG optimization: #parameters: 1218, #inputs: 1013, #subsample_inputs: 1013\n",
            "2019-04-01 06:42:49 | epoch #0 | computing loss before\n",
            "2019-04-01 06:42:49 | epoch #0 | performing update\n",
            "2019-04-01 06:42:49 | epoch #0 | computing gradient\n",
            "2019-04-01 06:42:49 | epoch #0 | gradient computed\n",
            "2019-04-01 06:42:49 | epoch #0 | computing descent direction\n",
            "2019-04-01 06:42:50 | epoch #0 | descent direction computed\n",
            "2019-04-01 06:42:50 | epoch #0 | backtrack iters: 0\n",
            "2019-04-01 06:42:50 | epoch #0 | computing loss after\n",
            "2019-04-01 06:42:50 | epoch #0 | optimization finished\n",
            "2019-04-01 06:42:50 | epoch #0 | Computing KL after\n",
            "2019-04-01 06:42:50 | epoch #0 | Computing loss after\n",
            "2019-04-01 06:42:50 | epoch #0 | Fitting baseline...\n",
            "2019-04-01 06:42:50 | epoch #0 | Saving snapshot...\n",
            "2019-04-01 06:42:50 | epoch #0 | Saved\n",
            "2019-04-01 06:42:50 | epoch #0 | Time 8.01 s\n",
            "2019-04-01 06:42:50 | epoch #0 | EpochTime 8.01 s\n",
            "---------------------------------------  --------------\n",
            "AverageDiscountedReturn                     4.75304\n",
            "AverageReturn                               4.9921\n",
            "Entropy                                     0.688329\n",
            "EnvExecTime                                 0.847786\n",
            "Extras/EpisodeRewardMean                    5\n",
            "Iteration                                   0\n",
            "LinearFeatureBaseline/ExplainedVariance    -2.87756e-08\n",
            "MaxReturn                                   5\n",
            "MinReturn                                   4\n",
            "NumTrajs                                 1013\n",
            "Perplexity                                  1.99039\n",
            "PolicyExecTime                              5.25753\n",
            "ProcessExecTime                             0.239677\n",
            "StdReturn                                   0.0885153\n",
            "policy/Entropy                              0.691807\n",
            "policy/KL                                   0.00989275\n",
            "policy/KLBefore                             1.52696e-08\n",
            "policy/LossAfter                           -0.000533063\n",
            "policy/LossBefore                          -1.73125e-06\n",
            "policy/dLoss                                0.000531331\n",
            "---------------------------------------  --------------\n",
            "2019-04-01 06:42:50 | epoch #1 | Obtaining samples...\n",
            "2019-04-01 06:42:50 | epoch #1 | Obtaining samples for iteration 1...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "0% [##############################] 100% | ETA: 00:00:00\n",
            "Total time elapsed: 00:00:07\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-04-01 06:42:57 | epoch #1 | Logging diagnostics...\n",
            "2019-04-01 06:42:57 | epoch #1 | Optimizing policy...\n",
            "2019-04-01 06:42:57 | epoch #1 | Computing loss before\n",
            "2019-04-01 06:42:57 | epoch #1 | Computing KL before\n",
            "2019-04-01 06:42:57 | epoch #1 | Optimizing\n",
            "2019-04-01 06:42:57 | epoch #1 | Start CG optimization: #parameters: 1218, #inputs: 1018, #subsample_inputs: 1018\n",
            "2019-04-01 06:42:57 | epoch #1 | computing loss before\n",
            "2019-04-01 06:42:57 | epoch #1 | performing update\n",
            "2019-04-01 06:42:57 | epoch #1 | computing gradient\n",
            "2019-04-01 06:42:57 | epoch #1 | gradient computed\n",
            "2019-04-01 06:42:57 | epoch #1 | computing descent direction\n",
            "2019-04-01 06:42:58 | epoch #1 | descent direction computed\n",
            "2019-04-01 06:42:58 | epoch #1 | backtrack iters: 0\n",
            "2019-04-01 06:42:58 | epoch #1 | computing loss after\n",
            "2019-04-01 06:42:58 | epoch #1 | optimization finished\n",
            "2019-04-01 06:42:58 | epoch #1 | Computing KL after\n",
            "2019-04-01 06:42:58 | epoch #1 | Computing loss after\n",
            "2019-04-01 06:42:58 | epoch #1 | Fitting baseline...\n",
            "2019-04-01 06:42:58 | epoch #1 | Saving snapshot...\n",
            "2019-04-01 06:42:58 | epoch #1 | Saved\n",
            "2019-04-01 06:42:58 | epoch #1 | Time 16.23 s\n",
            "2019-04-01 06:42:58 | epoch #1 | EpochTime 8.20 s\n",
            "---------------------------------------  -------------\n",
            "AverageDiscountedReturn                     4.7542\n",
            "AverageReturn                               4.99018\n",
            "Entropy                                     0.691801\n",
            "EnvExecTime                                 0.916491\n",
            "Extras/EpisodeRewardMean                    4.98\n",
            "Iteration                                   1\n",
            "LinearFeatureBaseline/ExplainedVariance     0.660687\n",
            "MaxReturn                                   5\n",
            "MinReturn                                   3\n",
            "NumTrajs                                 1018\n",
            "Perplexity                                  1.99731\n",
            "PolicyExecTime                              5.84212\n",
            "ProcessExecTime                             0.261647\n",
            "StdReturn                                   0.116859\n",
            "policy/Entropy                              0.675743\n",
            "policy/KL                                   0.00992123\n",
            "policy/KLBefore                             0\n",
            "policy/LossAfter                           -0.00114127\n",
            "policy/LossBefore                           3.3767e-08\n",
            "policy/dLoss                                0.0011413\n",
            "---------------------------------------  -------------\n",
            "2019-04-01 06:42:58 | epoch #2 | Obtaining samples...\n",
            "2019-04-01 06:42:58 | epoch #2 | Obtaining samples for iteration 2...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "0% [##############################] 100% | ETA: 00:00:00\n",
            "Total time elapsed: 00:00:07\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-04-01 06:43:05 | epoch #2 | Logging diagnostics...\n",
            "2019-04-01 06:43:05 | epoch #2 | Optimizing policy...\n",
            "2019-04-01 06:43:05 | epoch #2 | Computing loss before\n",
            "2019-04-01 06:43:05 | epoch #2 | Computing KL before\n",
            "2019-04-01 06:43:05 | epoch #2 | Optimizing\n",
            "2019-04-01 06:43:05 | epoch #2 | Start CG optimization: #parameters: 1218, #inputs: 1000, #subsample_inputs: 1000\n",
            "2019-04-01 06:43:05 | epoch #2 | computing loss before\n",
            "2019-04-01 06:43:05 | epoch #2 | performing update\n",
            "2019-04-01 06:43:05 | epoch #2 | computing gradient\n",
            "2019-04-01 06:43:05 | epoch #2 | gradient computed\n",
            "2019-04-01 06:43:05 | epoch #2 | computing descent direction\n",
            "2019-04-01 06:43:06 | epoch #2 | descent direction computed\n",
            "2019-04-01 06:43:06 | epoch #2 | backtrack iters: 0\n",
            "2019-04-01 06:43:06 | epoch #2 | computing loss after\n",
            "2019-04-01 06:43:06 | epoch #2 | optimization finished\n",
            "2019-04-01 06:43:06 | epoch #2 | Computing KL after\n",
            "2019-04-01 06:43:06 | epoch #2 | Computing loss after\n",
            "2019-04-01 06:43:06 | epoch #2 | Fitting baseline...\n",
            "2019-04-01 06:43:06 | epoch #2 | Saving snapshot...\n",
            "2019-04-01 06:43:06 | epoch #2 | Saved\n",
            "2019-04-01 06:43:06 | epoch #2 | Time 24.15 s\n",
            "2019-04-01 06:43:06 | epoch #2 | EpochTime 7.92 s\n",
            "---------------------------------------  --------------\n",
            "AverageDiscountedReturn                     4.75373\n",
            "AverageReturn                               4.996\n",
            "Entropy                                     0.676001\n",
            "EnvExecTime                                 0.902346\n",
            "Extras/EpisodeRewardMean                    5\n",
            "Iteration                                   2\n",
            "LinearFeatureBaseline/ExplainedVariance     0.675589\n",
            "MaxReturn                                   5\n",
            "MinReturn                                   3\n",
            "NumTrajs                                 1000\n",
            "Perplexity                                  1.966\n",
            "PolicyExecTime                              5.62656\n",
            "ProcessExecTime                             0.25995\n",
            "StdReturn                                   0.0773563\n",
            "policy/Entropy                              0.647502\n",
            "policy/KL                                   0.00991697\n",
            "policy/KLBefore                            -1.3626e-08\n",
            "policy/LossAfter                           -0.000339933\n",
            "policy/LossBefore                          -2.14577e-09\n",
            "policy/dLoss                                0.000339931\n",
            "---------------------------------------  --------------\n",
            "2019-04-01 06:43:06 | epoch #3 | Obtaining samples...\n",
            "2019-04-01 06:43:06 | epoch #3 | Obtaining samples for iteration 3...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "0% [##############################] 100% | ETA: 00:00:00\n",
            "Total time elapsed: 00:00:06\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-04-01 06:43:13 | epoch #3 | Logging diagnostics...\n",
            "2019-04-01 06:43:13 | epoch #3 | Optimizing policy...\n",
            "2019-04-01 06:43:13 | epoch #3 | Computing loss before\n",
            "2019-04-01 06:43:13 | epoch #3 | Computing KL before\n",
            "2019-04-01 06:43:13 | epoch #3 | Optimizing\n",
            "2019-04-01 06:43:13 | epoch #3 | Start CG optimization: #parameters: 1218, #inputs: 1006, #subsample_inputs: 1006\n",
            "2019-04-01 06:43:13 | epoch #3 | computing loss before\n",
            "2019-04-01 06:43:13 | epoch #3 | performing update\n",
            "2019-04-01 06:43:13 | epoch #3 | computing gradient\n",
            "2019-04-01 06:43:13 | epoch #3 | gradient computed\n",
            "2019-04-01 06:43:13 | epoch #3 | computing descent direction\n",
            "2019-04-01 06:43:13 | epoch #3 | descent direction computed\n",
            "2019-04-01 06:43:13 | epoch #3 | backtrack iters: 1\n",
            "2019-04-01 06:43:13 | epoch #3 | computing loss after\n",
            "2019-04-01 06:43:13 | epoch #3 | optimization finished\n",
            "2019-04-01 06:43:13 | epoch #3 | Computing KL after\n",
            "2019-04-01 06:43:13 | epoch #3 | Computing loss after\n",
            "2019-04-01 06:43:13 | epoch #3 | Fitting baseline...\n",
            "2019-04-01 06:43:13 | epoch #3 | Saving snapshot...\n",
            "2019-04-01 06:43:13 | epoch #3 | Saved\n",
            "2019-04-01 06:43:13 | epoch #3 | Time 31.58 s\n",
            "2019-04-01 06:43:13 | epoch #3 | EpochTime 7.42 s\n",
            "---------------------------------------  --------------\n",
            "AverageDiscountedReturn                     4.75649\n",
            "AverageReturn                               4.99801\n",
            "Entropy                                     0.647744\n",
            "EnvExecTime                                 0.851849\n",
            "Extras/EpisodeRewardMean                    5\n",
            "Iteration                                   3\n",
            "LinearFeatureBaseline/ExplainedVariance     0.671654\n",
            "MaxReturn                                   5\n",
            "MinReturn                                   4\n",
            "NumTrajs                                 1006\n",
            "Perplexity                                  1.91122\n",
            "PolicyExecTime                              5.17552\n",
            "ProcessExecTime                             0.244249\n",
            "StdReturn                                   0.0445435\n",
            "policy/Entropy                              0.67191\n",
            "policy/KL                                   0.00653902\n",
            "policy/KLBefore                            -1.18269e-08\n",
            "policy/LossAfter                           -0.00187737\n",
            "policy/LossBefore                           3.88273e-09\n",
            "policy/dLoss                                0.00187737\n",
            "---------------------------------------  --------------\n",
            "2019-04-01 06:43:13 | epoch #4 | Obtaining samples...\n",
            "2019-04-01 06:43:13 | epoch #4 | Obtaining samples for iteration 4...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "0% [######                        ] 100% | ETA: 00:00:05"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-09af41d54102>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# use n_epochs = 100 for practical example, n_epochs = 10 for quick demo, n_epochs = 1 for smoke testing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mrunner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/content/garage/garage/experiment/local_tf_runner.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, n_epochs, n_epoch_cycles, batch_size, plot, store_paths, pause_for_plot)\u001b[0m\n\u001b[1;32m    251\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprefix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'epoch #%d | '\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mcycle\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_epoch_cycles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 253\u001b[0;31m                     \u001b[0mpaths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobtain_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    254\u001b[0m                     \u001b[0mpaths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msampler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpaths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m                     \u001b[0mlast_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malgo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_once\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpaths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/garage/garage/experiment/local_tf_runner.py\u001b[0m in \u001b[0;36mobtain_samples\u001b[0;34m(self, itr, batch_size)\u001b[0m\n\u001b[1;32m    171\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_epoch_cycles\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Obtaining samples...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msampler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobtain_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msave_snapshot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpaths\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/garage/garage/tf/samplers/on_policy_vectorized_sampler.py\u001b[0m in \u001b[0;36mobtain_samples\u001b[0;34m(self, itr, batch_size, whole_paths)\u001b[0m\n\u001b[1;32m     55\u001b[0m             \u001b[0mpolicy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdones\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m             \u001b[0mactions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0magent_infos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpolicy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_actions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m             \u001b[0mpolicy_time\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/garage/garage/tf/policies/categorical_mlp_policy.py\u001b[0m in \u001b[0;36mget_actions\u001b[0;34m(self, observations)\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_actions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobservations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0mflat_obs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobservation_space\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten_n\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobservations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m         \u001b[0mprobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_f_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_obs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mactions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_space\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweighted_sample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mactions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprob\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/garage/garage/tf/misc/tensor_utils.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(*input_vals)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0msess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1332\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1336\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1317\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1319\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1405\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "LfG7tMG4LbtF",
        "colab_type": "code",
        "outputId": "c6356fd6-0e95-46dd-e335-8021bd9df25e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 378
        }
      },
      "cell_type": "code",
      "source": [
        "# test results\n",
        "n_experiments = 10\n",
        "row_all = []\n",
        "\n",
        "for i in range(n_experiments):\n",
        "  #print(\"experiment \", i+1)\n",
        "\n",
        "  # reset\n",
        "  obs_initial = env.reset()\n",
        "\n",
        "  # start\n",
        "  done = False\n",
        "  obs_i = obs_initial\n",
        "  while not done:\n",
        "    row_i = {}\n",
        "    row_i['exp'] = i + 1\n",
        "    row_i['obs'] = obs_i\n",
        "    act_i, _ = policy.get_action(obs_i)\n",
        "    row_i['act'] = act_i\n",
        "    obs_i, rew_i, done, _ = env.step(act_i)\n",
        "    row_i['obs'] = obs_i\n",
        "    row_i['rew'] = rew_i\n",
        "    row_all.append(row_i)\n",
        "    \n",
        "    if done: break\n",
        "    \n",
        "#env.close()\n",
        "\n",
        "import pandas as pd\n",
        "df = pd.DataFrame(row_all)\n",
        "pd.DataFrame({\n",
        "    'score': df.groupby('exp')['rew'].sum(),\n",
        "    'nstep': df.groupby('exp')['rew'].count()\n",
        "})"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>nstep</th>\n",
              "      <th>score</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>exp</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>7</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>7</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>13</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>8</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>7</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>8</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>10</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>7</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>10</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     nstep  score\n",
              "exp              \n",
              "1        7    5.0\n",
              "2        8    5.0\n",
              "3        7    5.0\n",
              "4       13    5.0\n",
              "5        8    5.0\n",
              "6        7    5.0\n",
              "7        8    5.0\n",
              "8       10    5.0\n",
              "9        7    5.0\n",
              "10      10    5.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "metadata": {
        "id": "nBxUpmnto1Qi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
